@article{governmentofpakistan2021PakistanLabourForce2021,
  title = {Pakistan {{Labour Force Survey}} 20-21},
  author = {Government Of Pakistan (2021)},
  year = {2021},
  journal = {Pakistan Bureau of Statistics},
  langid = {english},
  url = {https://www.pbs.gov.pk/sites/default/files/labour_force/publications/lfs2020_21/LFS_2020-21_Report.pdf},
  file = {C:\Users\Asad\Zotero\storage\7SE9AMQV\PAKISTAN LABOUR FORCE SURVEY 2020-21.pdf}
}

@article{nomanAssessmentOccupationalInjuries2021,
  title = {The {{Assessment}} of {{Occupational Injuries}} of {{Workers}} in {{Pakistan}}},
  author = {Noman, Muhammad and Mujahid, Nooreen and Fatima, Ambreen},
  year = {2021},
  month = dec,
  journal = {Safety and Health at Work},
  volume = {12},
  number = {4},
  pages = {452--461},
  issn = {2093-7911},
  doi = {10.1016/j.shaw.2021.06.001},
  urldate = {2024-09-19},
  abstract = {Background The prevailing global work scenario and deteriorating health facilities in economies indulge the risk perspective in the labor market model. This is the reason that the risk factor is cautiously attributed to wages and labor market efficiencies specifically in developing and emerging economies. In this respect, Occupational Injuries of Workers (OIW) is considered essential to demonstrate the risk and Occupational Health and Safety (OHS) setups given the constraints of the labor. Intuitively, the prime objective of this study is to make an assessment of the labor market considering the OIW through the indicators of industry division, employment status, occupational distribution, adopted treatment, gender and regionality. Methods The assessment strategy of the study has been categorized into trend analysis and Index Value Calculation (IVC) segments employing the data from 2001 to 2018. Results The pattern of the selected indicators of the OIW has been observed in the available data while the IVC estimations are considered through time and reference categories. The findings of both exercises revealed absolute and relative heterogeneities at both industry and occupational levels. Conclusion The consistency for gender and regional distribution of both assessments points out the need for effective policy initiatives. The study suggests separate analyses of industry and occupations for a better understanding of the OHS setups and up-gradation in Pakistan.},
  keywords = {Index Value Calculation,Labor Force Survey,Occupational Health and Safety,Occupational injuries},
  file = {C\:\\Users\\Asad\\Zotero\\storage\\XTXT5QZ8\\Noman et al. - 2021 - The Assessment of Occupational Injuries of Workers.pdf;C\:\\Users\\Asad\\Zotero\\storage\\BDXR56JL\\S2093791121000512.html}
}

@misc{Whistlers,
  title = {{Center for {Labour} {Research} Pakistan} },
  journal = {CLR},
  urldate = {2024-09-19},
  abstract = {THE WHISTLERS Do You Want to Report a Rights Violation?\hspace{0pt} Pakistan has a labour force of 65.5 million workers of which only 10.63 million are engaged in},
  langid = {american},
  url = {https://clr.org.pk/},
  file = {C:\Users\Asad\Zotero\storage\2MV8QKMI\the-whistlers.html}
}
@INPROCEEDINGS{YOLOv8BasedHelmet,
  author={Thakur, Divyanka and Pal, Priya and Jadhav, Amogh and Kable, Numaira and V, Bhagyalakshmi and Deshpande, Sonali},
  booktitle={2023 International Conference on Network, Multimedia and Information Technology (NMITCON)}, 
  title={YOLOv8- Based Helmet and Vest Detection System for Safety Assessment}, 
  year={2023},
  volume={},
  number={},
  pages={1-10},
  keywords={Personal protective equipment;Head;Runtime;Multimedia systems;Predictive models;Real-time systems;Safety;YOLOv8;helmet detection;vest detection;computer vision;deep learning;annotated images;NVIDIA DeepStream},
  doi={10.1109/NMITCON58196.2023.10275958}}
  @article{ComputerVisionTechnologiesForSafety,
  title = {Computer vision technologies for safety science and management in construction: A critical review and future research directions},
  journal = {Safety Science},
  volume = {135},
  pages = {105130},
  year = {2021},
  issn = {0925-7535},
  doi = {https://doi.org/10.1016/j.ssci.2020.105130},
  url = {https://www.sciencedirect.com/science/article/pii/S0925753520305270},
  author = {Brian H.W. Guo and Yang Zou and Yihai Fang and Yang Miang Goh and Patrick X.W. Zou},
  keywords = {Computer vision, Construction health and safety, Safety science, Safety culture, Safety Climate, Hazard, Safety management system, Digital technologies, Automation},
  abstract = {Recent years have seen growing interests in developing and applying computer vision technologies to solve safety problems in the construction industry. Despite the technological advancements, there is no research that exams the theoretical links between computer vision technology and safety science and management. Thus, the objectives of this paper are to: (1) investigate the current status of applying computer vision technology to construction safety, (2) examine the links between computer vision applications and key research themes of construction safety, (3) discuss the theoretical challenges of applying computer vision to construction safety, and (4) recommend future research directions. A five-step review approach was adopted to search and analyze peer-reviewed academic journal articles. A three-level computer vision development framework was proposed to categorized computer vision applications in the construction industry. The links between computer vision and three main safety research traditions: safety management system, behavior-based safety program, and safety culture, were discussed. The results suggest that the majority of past efforts were focused on object recognition, object tracking, and action recognition, with limited research focused on recognizing unsafe behavior. There are even fewer studies aimed at developing vision-based safety assessment and prediction systems. Based on the review findings, four future research directions are suggested: (1) develop and test a behavioral-cues-based safety climate measure, (2) develop safety behavior datasets, (3) develop a formal hazard identification and assessment model, and (4) develop criteria to evaluate the real impacts of vision-based technologies on safety performance.}
  }
  @article{DeepLearningForSiteSafety,
  title = {Deep learning for site safety: Real-time detection of personal protective equipment},
  journal = {Automation in Construction},
  volume = {112},
  pages = {103085},
  year = {2020},
  issn = {0926-5805},
  doi = {https://doi.org/10.1016/j.autcon.2020.103085},
  url = {https://www.sciencedirect.com/science/article/pii/S0926580519308325},
  author = {Nipun D. Nath and Amir H. Behzadan and Stephanie G. Paal},
  keywords = {Personal protective equipment (PPE), Construction safety, Deep learning, Transfer learning, Image dataset, Real-time object detection},
  abstract = {The leading causes of construction fatalities include traumatic brain injuries (resulted from fall and electrocution) and collisions (resulted from struck by objects). As a preventive step, the U.S. Occupational Safety and Health Administration (OSHA) requires that contractors enforce and monitor appropriate usage of personal protective equipment (PPE) of workers (e.g., hard hat and vest) at all times. This paper presents three deep learning (DL) models built on You-Only-Look-Once (YOLO) architecture to verify PPE compliance of workers; i.e., if a worker is wearing hard hat, vest, or both, from image/video in real-time. In the first approach, the algorithm detects workers, hats, and vests and then, a machine learning model (e.g., neural network and decision tree) verifies if each detected worker is properly wearing hat or vest. In the second approach, the algorithm simultaneously detects individual workers and verifies PPE compliance with a single convolutional neural network (CNN) framework. In the third approach, the algorithm first detects only the workers in the input image which are then cropped and classified by CNN-based classifiers (i.e., VGG-16, ResNet-50, and Xception) according to the presence of PPE attire. All models are trained on an in-house image dataset that is created using crowd-sourcing and web-mining. The dataset, named Pictor-v3, contains ~1,500 annotated images and ~4,700 instances of workers wearing various combinations of PPE components. It is found that the second approach achieves the best performance, i.e., 72.3% mean average precision (mAP), in real-world settings, and can process 11 frames per second (FPS) on a laptop computer which makes it suitable for real-time detection, as well as a good candidate for running on light-weight mobile devices. The closest alternative in terms of performance (67.93% mAP) is the third approach where VGG-16, ResNet-50, and Xception classifiers are assembled in a Bayesian framework. However, the first approach is the fastest among all and can process 13 FPS with 63.1% mAP. The crowed-sourced Pictor-v3 dataset and all trained models are publicly available to support the design and testing of other innovative applications for monitoring safety compliance, and advancing future research in automation in construction.}
  }
